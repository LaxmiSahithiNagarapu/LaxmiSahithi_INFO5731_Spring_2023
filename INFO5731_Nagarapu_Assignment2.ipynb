{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LaxmiSahithiNagarapu/LaxmiSahithi_INFO5731_Spring_2023/blob/main/INFO5731_Nagarapu_Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSdXHuqnwv9"
      },
      "source": [
        "# **INFO5731 Assignment Two**\n",
        "\n",
        "In this assignment, you will try to gather text data from open data source via web scraping or API. After that you need to clean the text data and syntactic analysis of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxodXh5n4xF"
      },
      "source": [
        "# **Question 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TenBkDJ5n95k"
      },
      "source": [
        "(40 points). Write a python program to collect text data from **either of the following sources** and save the data into a **csv file**:\n",
        "\n",
        "(1) Collect all the customer reviews of a product (you can choose any porduct) on amazon.\n",
        "\n",
        "(2) Collect the top 10000 User Reviews of a film recently in 2023 or 2022 (you can choose any film) from IMDB.\n",
        "\n",
        "(3) Collect all the reviews of the top 1000 most popular software from [G2](https://www.g2.com/) or [Capterra](https://www.capterra.com/)\n",
        "\n",
        "(4) Collect the abstracts of the top 10000 research papers by using the query \"machine learning\", \"data science\", \"artifical intelligence\", or \"information extraction\" from [Semantic Scholar](https://www.semanticscholar.org).\n",
        "\n",
        "(5) Collect all the information of the 904 narrators in the [Densho Digital Repository](https://ddr.densho.org/narrators/).\n",
        "\n",
        "(6) Collect the top 10000 tweets by using a hashtag (you can use any hashtag) from Twitter. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuFPKhC0m1fd",
        "outputId": "909fd4a0-79e0-4694-bb48-c6d95bf46634"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: selenium in c:\\users\\akatn\\anaconda3\\lib\\site-packages (4.8.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
            "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
            "Requirement already satisfied: trio~=0.17 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
            "Requirement already satisfied: cffi>=1.14 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
            "Requirement already satisfied: sniffio in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.0)\n",
            "Requirement already satisfied: idna in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
            "Requirement already satisfied: outcome in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Requirement already satisfied: async-generator>=1.9 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
            "Requirement already satisfied: sortedcontainers in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: wsproto>=0.14 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: pycparser in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
            "Requirement already satisfied: beautifulsoup4 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (4.11.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.3.1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'apt-get' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'apt' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'cp' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "# Write your code here\n",
        "\n",
        "import requests, openpyxl\n",
        "!pip install selenium\n",
        "!pip install beautifulsoup4\n",
        "!apt-get update\n",
        "from bs4 import BeautifulSoup as bs\n",
        "!apt install chromium-chromedriver\n",
        "import urllib.request as req\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "import pandas as pd\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FOWT-HkGdCA"
      },
      "outputs": [],
      "source": [
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait as wait\n",
        "from selenium import webdriver \n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('-headless')\n",
        "options.add_argument('-no-sandbox')\n",
        "options.add_argument('-disable-dev-shm-usage')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NXoD2IMGdCA",
        "outputId": "4e4e6ea3-788b-42cb-8996-e16866627e42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of data frame is 1099\n",
            "                                    Title_of_the_Review  \\\n",
            "0                             Worth a watch with family   \n",
            "1                                Sort of disappointed..   \n",
            "2     Questionable script (and Awkwafina is just the...   \n",
            "3     beautiful science fiction, fantasy and action ...   \n",
            "4                        A Ringer for a Great MCU Flick   \n",
            "...                                                 ...   \n",
            "1094        Wasted opportunity to make something unique   \n",
            "1095                               Best Marvel film yet   \n",
            "1096                                      Disappointing   \n",
            "1097                Perfect blend of almost everything!   \n",
            "1098                                    Nice One Marvel   \n",
            "\n",
            "                                    Review_of_the_movie  \n",
            "0     RATED 8/10 Language: English Source: Hotstar R...  \n",
            "1     I got to admit I wasn't particularly blown awa...  \n",
            "2     The characters are a bit incoherent and straig...  \n",
            "3     Everything comes in it beautiful science ficti...  \n",
            "4                                                        \n",
            "...                                                 ...  \n",
            "1094  This movie had a solid cast and some great mar...  \n",
            "1095  AWESOME ALL STAR ALL ASIAN-AMERICAN CAST. 100!...  \n",
            "1096  For the first time, the fight with two people ...  \n",
            "1097  Very well scripted for the character Shang-chi...  \n",
            "1098  Despite maintaining some of Marvels signature ...  \n",
            "\n",
            "[1099 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "titles = [] \n",
        "reviews= []\n",
        "link = 'https://www.imdb.com/title/tt9376612/reviews?ref_=tt_sa_3'\n",
        "driv = webdriver.Chrome('chromedriver',options=options)\n",
        "driv.get(link)\n",
        "for num in range(43):         \n",
        "  driv.find_element(By.CLASS_NAME, \"ipl-load-more__button\").click()\n",
        "  time.sleep(5)\n",
        "  All_Title = driv.find_elements(By.CLASS_NAME, \"title\")\n",
        "  All_Reviews = driv.find_elements(By.CLASS_NAME, \"text\")\n",
        "  \n",
        "for e, r in zip(All_Title, All_Reviews):\n",
        "      titles.append((e.text).replace('\\n',''))\n",
        "      reviews.append(r.text)\n",
        "      \n",
        "data_taken = pd.DataFrame(list(zip(titles, reviews)), columns =['Title_of_the_Review', 'Review_of_the_movie'])\n",
        "\n",
        "print(\"Length of data frame is\",len(data_taken))\n",
        "print(data_taken)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpMRCrRwN6Z"
      },
      "source": [
        "# **Question 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dCQEbDawWCw"
      },
      "source": [
        "(30 points). Write a python program to **clean the text data** you collected above and save the data in a new column in the csv file. The data cleaning steps include:\n",
        "\n",
        "(1) Remove noise, such as special characters and punctuations.\n",
        "\n",
        "(2) Remove numbers.\n",
        "\n",
        "(3) Remove stopwords by using the [stopwords list](https://gist.github.com/sebleier/554280).\n",
        "\n",
        "(4) Lowercase all texts\n",
        "\n",
        "(5) Stemming. \n",
        "\n",
        "(6) Lemmatization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vATjQNTY8buA",
        "outputId": "adbb0ca5-d2ba-4c92-8ae6-de952a0f83ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in c:\\users\\akatn\\anaconda3\\lib\\site-packages (3.7)\n",
            "Requirement already satisfied: tqdm in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from nltk) (4.64.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from nltk) (2022.3.15)\n",
            "Requirement already satisfied: joblib in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
            "Requirement already satisfied: click in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
            "Requirement already satisfied: colorama in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
          ]
        }
      ],
      "source": [
        "# Write your code here\n",
        "\n",
        "!pip install nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIk4A7FZGdCC",
        "outputId": "6815a81d-60d5-4f36-be82-dfbacbaabc44"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\akatn\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\akatn\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\akatn\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "# nltk.download('data')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "import numpy as np\n",
        "import nltk.corpus\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqpF7AjuGdCC",
        "outputId": "514d87fc-3362-40ea-b998-ea02be3fb715"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                    Title_of_the_Review  \\\n",
            "0                             Worth a watch with family   \n",
            "1                                Sort of disappointed..   \n",
            "2     Questionable script (and Awkwafina is just the...   \n",
            "3     beautiful science fiction, fantasy and action ...   \n",
            "5                                     Surprisingly good   \n",
            "...                                                 ...   \n",
            "1094        Wasted opportunity to make something unique   \n",
            "1095                               Best Marvel film yet   \n",
            "1096                                      Disappointing   \n",
            "1097                Perfect blend of almost everything!   \n",
            "1098                                    Nice One Marvel   \n",
            "\n",
            "                                    Review_of_the_movie  \n",
            "0     RATED 8/10 Language: English Source: Hotstar R...  \n",
            "1     I got to admit I wasn't particularly blown awa...  \n",
            "2     The characters are a bit incoherent and straig...  \n",
            "3     Everything comes in it beautiful science ficti...  \n",
            "5     I'll be honest - Marvel movies are not in my t...  \n",
            "...                                                 ...  \n",
            "1094  This movie had a solid cast and some great mar...  \n",
            "1095  AWESOME ALL STAR ALL ASIAN-AMERICAN CAST. 100!...  \n",
            "1096  For the first time, the fight with two people ...  \n",
            "1097  Very well scripted for the character Shang-chi...  \n",
            "1098  Despite maintaining some of Marvels signature ...  \n",
            "\n",
            "[944 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "df=data_taken\n",
        "df=df[df[\"Review_of_the_movie\"]!= \"\"] #Removing null review\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTNhf99fGdCC",
        "outputId": "5c9013fc-685e-49d5-ff0b-3a57b71af25e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     C:\\Users\\akatn\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "C:\\Users\\akatn\\AppData\\Local\\Temp\\ipykernel_4048\\1421495494.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:,[\"clean_txt\"]]=df[\"Review_of_the_movie\"].apply(lambda ele: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", ele))\n",
            "C:\\Users\\akatn\\AppData\\Local\\Temp\\ipykernel_4048\\1421495494.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:,[\"clean_txt\"]]=df[\"clean_txt\"].apply(lambda ele: re.sub(r\"\\d+\", \"\", ele))\n",
            "C:\\Users\\akatn\\AppData\\Local\\Temp\\ipykernel_4048\\1421495494.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:,[\"clean_txt\"]]=df[\"clean_txt\"].apply(lambda string: ' '.join([w for w in string.split() if w not in (stopword_list)]))\n",
            "C:\\Users\\akatn\\AppData\\Local\\Temp\\ipykernel_4048\\1421495494.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:,[\"clean_txt\"]]=df[\"clean_txt\"].str.lower()\n",
            "C:\\Users\\akatn\\AppData\\Local\\Temp\\ipykernel_4048\\1421495494.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:,[\"tokens\"]] = df[\"clean_txt\"].apply(lambda x: word_tokenize(x))\n",
            "C:\\Users\\akatn\\AppData\\Local\\Temp\\ipykernel_4048\\1421495494.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:,['text_stem']] = df[\"tokens\"].apply(lambda x: word_stemmer(x))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                    Title_of_the_Review  \\\n",
            "0                             Worth a watch with family   \n",
            "1                                Sort of disappointed..   \n",
            "2     Questionable script (and Awkwafina is just the...   \n",
            "3     beautiful science fiction, fantasy and action ...   \n",
            "5                                     Surprisingly good   \n",
            "...                                                 ...   \n",
            "1094        Wasted opportunity to make something unique   \n",
            "1095                               Best Marvel film yet   \n",
            "1096                                      Disappointing   \n",
            "1097                Perfect blend of almost everything!   \n",
            "1098                                    Nice One Marvel   \n",
            "\n",
            "                                    Review_of_the_movie  \\\n",
            "0     RATED 8/10 Language: English Source: Hotstar R...   \n",
            "1     I got to admit I wasn't particularly blown awa...   \n",
            "2     The characters are a bit incoherent and straig...   \n",
            "3     Everything comes in it beautiful science ficti...   \n",
            "5     I'll be honest - Marvel movies are not in my t...   \n",
            "...                                                 ...   \n",
            "1094  This movie had a solid cast and some great mar...   \n",
            "1095  AWESOME ALL STAR ALL ASIAN-AMERICAN CAST. 100!...   \n",
            "1096  For the first time, the fight with two people ...   \n",
            "1097  Very well scripted for the character Shang-chi...   \n",
            "1098  Despite maintaining some of Marvels signature ...   \n",
            "\n",
            "                                              clean_txt  \\\n",
            "0     rated language english source hotstar recommen...   \n",
            "1     i got admit i wasnt particularly blown away an...   \n",
            "2     the characters bit incoherent straight contrad...   \n",
            "3     everything comes beautiful science fiction bea...   \n",
            "5     ill honest marvel movies top even within marve...   \n",
            "...                                                 ...   \n",
            "1094  this movie solid cast great martial arts fight...   \n",
            "1095  awesome all star all asianamerican cast this b...   \n",
            "1096  for first time fight two people amazing farthe...   \n",
            "1097  very well scripted character shangchi this mar...   \n",
            "1098  despite maintaining marvels signature sometime...   \n",
            "\n",
            "                                                 tokens  \\\n",
            "0     [rated, language, english, source, hotstar, re...   \n",
            "1     [i, got, admit, i, wasnt, particularly, blown,...   \n",
            "2     [the, characters, bit, incoherent, straight, c...   \n",
            "3     [everything, comes, beautiful, science, fictio...   \n",
            "5     [ill, honest, marvel, movies, top, even, withi...   \n",
            "...                                                 ...   \n",
            "1094  [this, movie, solid, cast, great, martial, art...   \n",
            "1095  [awesome, all, star, all, asianamerican, cast,...   \n",
            "1096  [for, first, time, fight, two, people, amazing...   \n",
            "1097  [very, well, scripted, character, shangchi, th...   \n",
            "1098  [despite, maintaining, marvels, signature, som...   \n",
            "\n",
            "                                              text_stem  \\\n",
            "0     [rate, languag, english, sourc, hotstar, recom...   \n",
            "1     [i, got, admit, i, wasnt, particular, blown, a...   \n",
            "2     [the, charact, bit, incoher, straight, contrad...   \n",
            "3     [everyth, come, beauti, scienc, fiction, beaut...   \n",
            "5     [ill, honest, marvel, movi, top, even, within,...   \n",
            "...                                                 ...   \n",
            "1094  [this, movi, solid, cast, great, martial, art,...   \n",
            "1095  [awesom, all, star, all, asianamerican, cast, ...   \n",
            "1096  [for, first, time, fight, two, peopl, amaz, fa...   \n",
            "1097  [veri, well, script, charact, shangchi, this, ...   \n",
            "1098  [despit, maintain, marvel, signatur, sometim, ...   \n",
            "\n",
            "                                               text_lem  \n",
            "0     [rated, language, english, source, hotstar, re...  \n",
            "1     [i, got, admit, i, wasnt, particularly, blown,...  \n",
            "2     [the, character, bit, incoherent, straight, co...  \n",
            "3     [everything, come, beautiful, science, fiction...  \n",
            "5     [ill, honest, marvel, movie, top, even, within...  \n",
            "...                                                 ...  \n",
            "1094  [this, movie, solid, cast, great, martial, art...  \n",
            "1095  [awesome, all, star, all, asianamerican, cast,...  \n",
            "1096  [for, first, time, fight, two, people, amazing...  \n",
            "1097  [very, well, scripted, character, shangchi, th...  \n",
            "1098  [despite, maintaining, marvel, signature, some...  \n",
            "\n",
            "[944 rows x 6 columns]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\akatn\\AppData\\Local\\Temp\\ipykernel_4048\\1421495494.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:,['text_lem']] = df[\"tokens\"].apply(lambda x: word_lemmatizer(x))\n"
          ]
        }
      ],
      "source": [
        "nltk.download('omw-1.4')\n",
        "stopword_list = stopwords.words('english')\n",
        "snow_stemmer = SnowballStemmer(\"english\")\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def clean(df):\n",
        "    df.loc[:,[\"clean_txt\"]]=df[\"Review_of_the_movie\"].apply(lambda ele: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", ele))\n",
        "    df.loc[:,[\"clean_txt\"]]=df[\"clean_txt\"].apply(lambda ele: re.sub(r\"\\d+\", \"\", ele))\n",
        "    df.loc[:,[\"clean_txt\"]]=df[\"clean_txt\"].apply(lambda string: ' '.join([w for w in string.split() if w not in (stopword_list)]))\n",
        "    df.loc[:,[\"clean_txt\"]]=df[\"clean_txt\"].str.lower()\n",
        "    df.loc[:,[\"tokens\"]] = df[\"clean_txt\"].apply(lambda x: word_tokenize(x))\n",
        "    def word_stemmer(text):\n",
        "      stem_text = [snow_stemmer.stem(i) for i in text]\n",
        "      return stem_text\n",
        "    df.loc[:,['text_stem']] = df[\"tokens\"].apply(lambda x: word_stemmer(x))\n",
        "    def word_lemmatizer(text):\n",
        "      lem_text = [lemmatizer.lemmatize(i) for i in text]\n",
        "      return lem_text\n",
        "    df.loc[:,['text_lem']] = df[\"tokens\"].apply(lambda x: word_lemmatizer(x))\n",
        "    return df\n",
        "c = clean(df)\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mmYIfN8eYV"
      },
      "source": [
        "# **Question 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsi2y4z88ngX"
      },
      "source": [
        "(30 points). Write a python program to conduct **syntax and structure analysis** of the clean text you just saved above. The syntax and structure analysis includes: \n",
        "\n",
        "(1) Parts of Speech (POS) Tagging: Tag Parts of Speech of each word in the text, and calculate the total number of N(oun), V(erb), Adj(ective), Adv(erb), respectively.\n",
        "\n",
        "(2) Constituency Parsing and Dependency Parsing: print out the constituency parsing trees and dependency parsing trees of all the sentences. Using one sentence as an example to explain your understanding about the constituency parsing tree and dependency parsing tree.\n",
        "\n",
        "(3) Named Entity Recognition: Extract all the entities such as person names, organizations, locations, product names, and date from the clean texts, calculate the count of each entity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQKnPjPDHJHr",
        "outputId": "e6b6f380-0754-46ad-9856-a9df22158d9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting en-core-web-sm==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
            "     ---------------------------------------- 12.8/12.8 MB 4.0 MB/s eta 0:00:00\n",
            "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.5.0) (3.5.0)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.21.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.5)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.7)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.11.3)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.64.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.5)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (21.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: setuptools in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (67.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.9)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: colorama in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.4.6)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\akatn\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.1)\n",
            "Installing collected packages: en-core-web-sm\n",
            "Successfully installed en-core-web-sm-3.5.0\n",
            "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "# Write your code here\n",
        "\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ct898xaxGdCE",
        "outputId": "778b446d-bf45-4aeb-b9ee-f564adf18bc1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     C:\\Users\\akatn\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "UsageError: Line magic function `%tensorflow_version` not found.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "import spacy\n",
        "nlp=spacy.load('en_core_web_sm')\n",
        "%tensorflow_version 2.x\n",
        "!pip install benepar\n",
        "import benepar\n",
        "benepar.download('benepar_en2')\n",
        "from benepar.spacy_plugin import BeneparComponent\n",
        "benepar.download('benepar_en3')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CkUTNkaCGdCE",
        "outputId": "c5e001f3-96cd-4230-be04-054914620492"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0        [rated, -, VERB, -, VBN]\n",
            "1            [i, -, PRON, -, PRP]\n",
            "2           [the, -, PRON, -, DT]\n",
            "3    [everything, -, PRON, -, NN]\n",
            "5            [ill, -, ADJ, -, JJ]\n",
            "Name: pos, dtype: object\n",
            "944\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\akatn\\AppData\\Local\\Temp\\ipykernel_4048\\3209320375.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['pos']=df['tokens'].apply(lambda x: syn_struc(x))\n"
          ]
        }
      ],
      "source": [
        "def syn_struc(text):\n",
        "  for t in text:\n",
        "    for token in nlp(t):\n",
        "      return [token.text, '-',token.pos_,'-',token.tag_]\n",
        "df['pos']=df['tokens'].apply(lambda x: syn_struc(x))\n",
        "print(df['pos'].head())\n",
        "print(len(df['pos']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWOtvT2rHNWy"
      },
      "source": [
        "**Write your explanations of the constituency parsing tree and dependency parsing tree here (Question 3-2):** "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting a sentence's dependencies in order to reflect its grammatical structure is known as dependency parsing. It serves as an example of how headwords and their dependents are interdependent. Dependence tags highlight the connections between two words in a phrase.\n",
        "\n",
        "Constituency For analytical purposes, parsing is the process of dividing words into smaller parts, also referred to as constituents. These phrases fall under the same grammar group as Noun phrases and Verb phrase.\n"
      ],
      "metadata": {
        "id": "5G6EmtaVGr3D"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}